FROM ghcr.io/ggml-org/llama.cpp:server-cuda

RUN curl -Ls https://github.com/mostlygeek/llama-swap/releases/download/v96/llama-swap_96_linux_amd64.tar.gz | tar xz -C /usr/local/bin
